# Modo Dual - Dual-Write/Dual-Read

## üìñ Descripci√≥n

El **DualTareaRepository** implementa un patr√≥n de migraci√≥n sin downtime que permite escribir y leer desde dos bases de datos simult√°neamente (Peewee/SQL y MongoDB).

Antes de cualquier operaci√≥n de **escritura**, se realiza un **ping en paralelo** a ambas bases de datos. Si una no responde, se avisa con un warning y la operaci√≥n se dirige √∫nicamente a la BDD disponible.

## üéØ Objetivo

Facilitar la migraci√≥n de datos entre diferentes sistemas de persistencia sin interrumpir el servicio, siguiendo las mejores pr√°cticas de la arquitectura hexagonal.

---

## üèóÔ∏è Arquitectura

### Diagrama de Componentes

```mermaid
graph TB
    A[Application Layer] --> B{Container}
    B -->|ORM=peewee| C[PeeweeTareaRepository]
    B -->|ORM=mongo| D[MongoTareaRepository]
    B -->|ORM=dual| E[DualTareaRepository]

    E --> P["üèì Ping paralelo (max_workers=4)"]
    P -->|ping_sql| G[(SQL/Postgres)]
    P -->|ping_mongo| H[(MongoDB)]

    P -->|ambas OK| F[Dual-Write paralelo]
    P -->|solo SQL OK| C
    P -->|solo Mongo OK| D
    P -->|ninguna OK| X[‚ùå Exception]

    F -->|Thread 1| C
    F -->|Thread 2| D
```

### Patr√≥n de Dise√±o

El repositorio dual implementa el **patr√≥n Adapter** de la arquitectura hexagonal:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Application Layer                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Use Cases    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Repository  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Domain     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ    ‚îÇ   Port       ‚îÇ    ‚îÇ   Models     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Infrastructure Layer                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              DualTareaRepository                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Peewee         ‚îÇ      ‚îÇ  MongoDB               ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Repository     ‚îÇ      ‚îÇ  Repository            ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                           ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  SQLite/    ‚îÇ            ‚îÇ    MongoDB     ‚îÇ
        ‚îÇ  PostgreSQL ‚îÇ            ‚îÇ                ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Estrategia de Migraci√≥n

### Fase 1: Dual-Write con Ping previo

```mermaid
sequenceDiagram
    participant Client
    participant DualRepo as DualTareaRepository
    participant Executor as ThreadPoolExecutor
    participant SQL as Peewee Repo
    participant Mongo as MongoDB Repo

    Client->>DualRepo: save(tarea) / eliminar(id)
    note over DualRepo,Executor: üèì Ping en PARALELO (ambas BDD a la vez)
    DualRepo->>Executor: submit(_ping_sql)
    DualRepo->>Executor: submit(_ping_mongo)
    Executor-->>DualRepo: sql_ok, mongo_ok

    alt Ninguna disponible
        DualRepo-->>Client: ‚ùå Exception inmediata
    else Solo SQL disponible
        DualRepo-->>Client: ‚ö†Ô∏è Warning ‚Äî guardando solo en SQL
        DualRepo->>SQL: operaci√≥n
    else Solo Mongo disponible
        DualRepo-->>Client: ‚ö†Ô∏è Warning ‚Äî guardando solo en MongoDB
        DualRepo->>Mongo: operaci√≥n
    else Ambas disponibles
        par Escritura dual paralela
            DualRepo->>SQL: operaci√≥n
            SQL-->>DualRepo: result/error
        and
            DualRepo->>Mongo: operaci√≥n
            Mongo-->>DualRepo: result/error
        end
        DualRepo-->>Client: ‚úÖ Success (o ‚ö†Ô∏è si una falla en escritura)
    end
```

**Operaciones con ping previo:**
- **save()**: Ping ‚Üí escribe en BDD disponibles (ambas, una, o falla)
- **eliminar()**: Ping ‚Üí elimina en BDD disponibles (ambas, una, o falla)

### Fase 2: Dual-Read (Lectura con Fallback)

```mermaid
sequenceDiagram
    participant Client
    participant DualRepo as DualTareaRepository
    participant SQL as Peewee Repo
    participant Mongo as MongoDB Repo
    
    Client->>DualRepo: get(id)
    DualRepo->>SQL: get(id)
    
    alt SQL Success
        SQL-->>DualRepo: tarea
        DualRepo-->>Client: tarea
    else SQL Fail or Not Found
        SQL-->>DualRepo: null/error
        DualRepo->>Mongo: get(id)
        Mongo-->>DualRepo: tarea
        DualRepo-->>Client: tarea
    end
```

**Operaciones:**
- **get()**: Lee de Peewee (principal), con fallback a MongoDB
- **list()**: Lee de Peewee (principal), con fallback a MongoDB

---

## üìã Uso

### Activar el Modo Dual

Para habilitar el modo dual, configura la variable de entorno `ORM`:

#### Windows PowerShell:
```powershell
$env:ORM="dual"
uvicorn backend_fastapi.main:app --reload
```

#### Linux/Mac:
```bash
export ORM=dual
uvicorn backend_fastapi.main:app --reload
```

### Desactivar el Modo Dual

#### Volver a Peewee (por defecto):
```powershell
$env:ORM="peewee"
# o simplemente no definir ORM
```

#### Usar solo MongoDB:
```powershell
$env:ORM="mongo"
```

---

## üîç Caracter√≠sticas

### ‚úÖ Ping paralelo previo a escrituras

Antes de cada `save()` o `eliminar()`, se hace ping en paralelo a ambas BDD. La latencia del ping = `max(ping_sql, ping_mongo)` en lugar de la suma:

```python
# Pings en paralelo ‚Äî no suma latencias, solo espera el m√°s lento
future_sql   = executor.submit(_ping_sql)
future_mongo = executor.submit(_ping_mongo)
sql_ok       = future_sql.result(timeout=4)
mongo_ok     = future_mongo.result(timeout=4)
```

### ‚úÖ Ejecuci√≥n Paralela con pool ampliado

El pool ahora tiene **4 workers**: 2 para pings y 2 para operaciones reales, evitando que los pings bloqueen las escrituras:

```python
# Pool de threads global ‚Äî 4 workers (antes 2)
executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="DualRepo")
```

### ‚úÖ Imports a nivel de m√≥dulo

`psycopg` y `MongoClient` se importan **una sola vez** al arrancar el m√≥dulo (no en cada llamada a `_ping_sql`/`_ping_mongo`), eliminando el overhead repetido de import:

### ‚úÖ Tolerancia a Fallos con dispatch condicional

```mermaid
flowchart TD
    A[save / eliminar] --> P["üèì Ping paralelo"]
    P --> B{sql_ok}
    P --> C{mongo_ok}

    B -- No --> OnlyMongo{mongo_ok?}
    B -- S√≠ --> BothCheck{mongo_ok?}

    OnlyMongo -- S√≠ --> M["‚ö†Ô∏è Solo MongoDB"]
    OnlyMongo -- No --> X["‚ùå Exception inmediata"]

    BothCheck -- No --> S["‚ö†Ô∏è Solo SQL"]
    BothCheck -- S√≠ --> Dual["üîÑ Dual-Write paralelo"]

    Dual --> R{Resultado escritura}
    R -->|Ambos OK| OK["‚úÖ Success"]
    R -->|Uno OK| W["‚ö†Ô∏è Warning"]
    R -->|Ambos Fail| E["‚ùå Exception"]
```

- Si **ninguna** BDD hace ping ‚Üí excepci√≥n **inmediata** (sin intentar escribir)
- Si **solo una** BDD hace ping ‚Üí avisa con `‚ö†Ô∏è warning` y escribe en la disponible
- Si **ambas** hacen ping ‚Üí escritura dual en paralelo
- Los errores se registran con logging detallado

### ‚úÖ Logging Detallado

El repositorio dual incluye emojis y mensajes claros para facilitar el debugging:

```
üèì Ping previo a BDD para save de <uuid>...
üî¥ Mongo no disponible: <error>          ‚Üê BDD ca√≠da
‚ö†Ô∏è MongoDB no disponible. save de <uuid> se guardar√° SOLO en SQL.
‚úì Operaci√≥n Peewee (solo) completada

# Cuando ambas est√°n OK:
üèì Ping previo a BDD para save de <uuid>...
üîÑ save dual iniciado para <uuid>
‚úì Operaci√≥n Peewee completada
‚úì Operaci√≥n MongoDB completada
‚úÖ save dual exitoso para <uuid>
```

**Niveles de Log:**
- `INFO`: Inicio/completado de operaciones dual
- `WARNING`: Una BDD no disponible (ping) o fall√≥ en escritura
- `ERROR`: Ninguna BDD disponible, o ambas fallaron en escritura
- `DEBUG`: Operaciones individuales completadas

---

## üß™ Testing

Puedes probar el modo dual ejecutando los tests:

```powershell
# Test del repositorio dual
pytest test/test_dual_repository.py -v

# Test de todos los repositorios
pytest test/ -v
```

---

## ‚ö†Ô∏è Consideraciones

### Consistencia Eventual

- Si una base de datos falla temporalmente, los datos pueden quedar inconsistentes
- Se recomienda implementar un proceso de sincronizaci√≥n/reconciliaci√≥n peri√≥dico

### Performance

- El modo dual a√±ade overhead por la ejecuci√≥n paralela
- Es ideal para migraciones, no como soluci√≥n permanente
- El tiempo de respuesta es el tiempo del repositorio m√°s lento + overhead del threading

### Transacciones

- Las transacciones NO son at√≥micas entre ambas bases de datos
- Si necesitas atomicidad completa, considera usar un patr√≥n Saga
- Cada repositorio maneja sus propias transacciones independientemente

---

## üîß Configuraci√≥n Avanzada

### Personalizar el Repositorio Dual

Puedes inyectar instancias personalizadas de los repositorios:

```python
from infrastructure.dual.repository.tarea_repository import DualTareaRepository
from infrastructure.peewee.repository.tarea_repository import PeeweeTareaRepository
from infrastructure.mongo.repository.tarea_repository import MongoTareaRepository

# Repositorios personalizados
sql_repo = PeeweeTareaRepository()
mongo_repo = MongoTareaRepository()

# Inyecci√≥n manual
dual_repo = DualTareaRepository(
    sql_repository=sql_repo,
    mongo_repository=mongo_repo
)
```

### Ajustar el ThreadPoolExecutor

El executor se define como variable global en `tarea_repository.py`. Actualmente usa **4 workers**: 2 reservados para los pings paralelos y 2 para las operaciones reales:

```python
# Pool con 4 workers ‚Äî ajustar si hay m√°s concurrencia
executor = ThreadPoolExecutor(
    max_workers=4,  # 2 pings + 2 operaciones
    thread_name_prefix="DualRepo"
)
```

### Ajustar timeouts de ping

Los timeouts se configuran como constantes al inicio del m√≥dulo:

```python
_PING_TIMEOUT_SECS = 3   # timeout para psycopg (Postgres)
_PING_TIMEOUT_MS   = 3000  # timeout para MongoClient
```

---

## üõ†Ô∏è Gu√≠a para Realizar Cambios

### Estructura de Archivos

```
infrastructure/
‚îî‚îÄ‚îÄ dual/
    ‚îú‚îÄ‚îÄ repository/
    ‚îÇ   ‚îî‚îÄ‚îÄ tarea_repository.py    # ‚Üê Archivo principal
    ‚îî‚îÄ‚îÄ README.md                   # ‚Üê Este archivo
```

### Agregar Nuevos M√©todos al Repositorio

Si necesitas agregar nuevos m√©todos al `TareaRepository` y hacerlos compatibles con el modo dual:

**1. Agregar al Port (Interfaz):**
```python
# core/domain/ports/tarea_repository.py
class TareaRepository(ABC):
    @abstractmethod
    def nuevo_metodo(self, tarea_id: UUID) -> Tarea:
        pass
```

**2. Implementar en Repositorios Base:**
```python
# infrastructure/peewee/repository/tarea_repository.py
class PeeweeTareaRepository(TareaRepository):
    def nuevo_metodo(self, tarea_id: UUID) -> Tarea:
        # Implementaci√≥n Peewee
        pass

# infrastructure/mongo/repository/tarea_repository.py
class MongoTareaRepository(TareaRepository):
    def nuevo_metodo(self, tarea_id: UUID) -> Tarea:
        # Implementaci√≥n MongoDB
        pass
```

**3. Implementar en DualTareaRepository:**

**Para operaciones de escritura (con ping previo):**
```python
def nuevo_metodo_write(self, tarea: Tarea) -> None:
    """Operaci√≥n de escritura dual con ping previo."""
    self._dispatch_escritura(
        operacion="nuevo_metodo_write",
        sql_func=lambda: self._sql_repo.nuevo_metodo_write(tarea),
        mongo_func=lambda: self._mongo_repo.nuevo_metodo_write(tarea),
        entidad_id=tarea.id,
    )
```

El m√©todo `_dispatch_escritura` se encarga del ping, dispatch condicional y logging autom√°ticamente.

**Para operaciones de lectura (Dual-Read):**
```python
def nuevo_metodo_read(self, tarea_id: UUID) -> Tarea | None:
    """Operaci√≥n de lectura con fallback."""
    logger.debug(f"üîç Buscando tarea {tarea_id}")
    
    # Intenta leer de Peewee primero
    try:
        result = self._sql_repo.nuevo_metodo_read(tarea_id)
        if result is not None:
            return result
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error en Peewee: {e}")
    
    # Fallback a MongoDB
    try:
        result = self._mongo_repo.nuevo_metodo_read(tarea_id)
        if result is not None:
            logger.info(f"‚úì Obtenido de MongoDB (fallback)")
            return result
    except Exception as e:
        logger.error(f"‚ùå Error en MongoDB: {e}")
    
    return None
```

### Modificar el Comportamiento del ThreadPool

Para cambiar el n√∫mero de workers o el comportamiento del executor:

```python
# Linea 16 en tarea_repository.py
# Opci√≥n 1: M√°s workers para mayor concurrencia
executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="DualRepo")

# Opci√≥n 2: Usar ProcessPoolExecutor para operaciones CPU-bound
from concurrent.futures import ProcessPoolExecutor
executor = ProcessPoolExecutor(max_workers=2)
```

### Cambiar la Estrategia de Fallback

Para modificar cu√°l repositorio es el "primario":

```python
def get(self, tarea_id: UUID) -> Tarea | None:
    # Cambiar el orden de los intentos
    try:
        # Intentar MongoDB primero
        tarea = self._mongo_repo.get(tarea_id)
        if tarea is not None:
            return tarea
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error en MongoDB: {e}")
    
    # Fallback a Peewee
    try:
        tarea = self._sql_repo.get(tarea_id)
        if tarea is not None:
            logger.info(f"‚úì Obtenido de Peewee (fallback)")
            return tarea
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error en Peewee: {e}")
    
    return None
```

### Agregar M√©tricas/Monitoreo

Para agregar m√©tricas de rendimiento:

```python
import time
from prometheus_client import Counter, Histogram

# M√©tricas
dual_write_duration = Histogram(
    'dual_write_duration_seconds',
    'Duration of dual-write operations',
    ['repository']
)
dual_write_errors = Counter(
    'dual_write_errors_total',
    'Total errors in dual-write operations',
    ['repository', 'error_type']
)

def save(self, tarea: Tarea) -> None:
    start_time = time.time()
    
    _, sql_error, _, mongo_error = self._execute_parallel(...)
    
    # Registrar m√©tricas
    dual_write_duration.labels(repository='sql').observe(time.time() - start_time)
    dual_write_duration.labels(repository='mongo').observe(time.time() - start_time)
    
    if sql_error:
        dual_write_errors.labels(repository='sql', error_type=type(sql_error).__name__).inc()
    if mongo_error:
        dual_write_errors.labels(repository='mongo', error_type=type(mongo_error).__name__).inc()
```

---

## üêõ Debugging y Troubleshooting

### Logs no aparecen

Aseg√∫rate de que el logging est√© configurado correctamente:

```python
import logging

# Configurar nivel de logging
logging.basicConfig(
    level=logging.DEBUG,  # Cambiar a INFO en producci√≥n
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### Timeouts en operaciones paralelas

El `ThreadPoolExecutor` no tiene timeout por defecto. Para agregar:

```python
from concurrent.futures import wait, FIRST_COMPLETED

# En _execute_parallel
future_sql = executor.submit(sql_func)
future_mongo = executor.submit(mongo_func)

# Esperar con timeout
done, not_done = wait(
    [future_sql, future_mongo],
    timeout=10.0,  # 10 segundos
    return_when=FIRST_COMPLETED
)

if not_done:
    # Cancelar las que no terminaron
    for future in not_done:
        future.cancel()
```

### Deadlocks

Si hay deadlocks:
1. Verificar que los repositorios base no compartan recursos
2. Asegurar que no haya locks anidados entre SQLAlchemy y MongoDB
3. Considerar usar `asyncio` en lugar de threads si hay mucha I/O

---

## üìö Referencias

- Ver `roadmap.md` secci√≥n 6: "Estrategia de Migraci√≥n (Dual-Write / Dual-Read)"
- Patr√≥n de Arquitectura Hexagonal: Ports & Adapters
- [Parallel Execution con ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)

---

## üéì Ejemplo Completo

```python
# 1. Configurar variable de entorno
import os
os.environ["ORM"] = "dual"

# 2. Obtener el caso de uso (autom√°ticamente usar√° DualTareaRepository)
from infrastructure.container import get_crear_tarea_use_case
from core.application.crear_tarea import CrearTareaCommand
from core.domain.models.tarea import EstadoTarea

use_case = get_crear_tarea_use_case()

# 3. Ejecutar operaci√≥n - se escribir√° en AMBAS bases de datos
cmd = CrearTareaCommand(
    titulo="Tarea de prueba",
    descripcion="Esta tarea se guardar√° en SQLite Y MongoDB",
    estado=EstadoTarea.PENDIENTE
)

tarea = use_case.execute(cmd)
print(f"Tarea {tarea.id} creada en ambas bases de datos")
```

---

**√öltima actualizaci√≥n:** 2026-02-21 ‚Äî Ping paralelo previo a escrituras, imports a nivel de m√≥dulo, pool ampliado a 4 workers, dispatch condicional por disponibilidad de BDD.
